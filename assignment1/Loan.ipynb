{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('loan.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Loan_ID\", axis=1, inplace=True)\n",
    "# Checking the Missing Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Task1 deal with NULL rows, you can either choose to drop them or replace them with mean or other value #\n",
    "################################################################################\n",
    "\n",
    "df[\"Credit_History\"] = df[\"Credit_History\"].astype(str)\n",
    "\n",
    "# fill numeric values with mean\n",
    "mean = df.mean(numeric_only=True)\n",
    "df = df.fillna(value=mean)\n",
    "\n",
    "# fill string values with mode\n",
    "mode = df.mode()\n",
    "mode = {k: mode[k][0] for k in mode}\n",
    "df = df.fillna(value=mode)\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Task2 deal with categorical features\n",
    "# Tip use pd.get_dummies. \n",
    "################################################################################\n",
    "\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# drop useless columns for 2-value properties\n",
    "df = df.drop([\"Gender_Female\", \"Married_No\", \"Education_Not Graduate\", \"Self_Employed_No\", \"Loan_Status_N\", \"Credit_History_0.0\"], axis=1)\n",
    "\n",
    "df.head()\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalization(data):\n",
    "    range = np.max(data) - np.min(data)\n",
    "    return (data - np.min(data)) / range\n",
    "\n",
    "\n",
    "# normalize data\n",
    "\n",
    "for key in [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\"]:\n",
    "    df[key] = np.sqrt(df[key])\n",
    "    df[key] = normalization(df[key])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, r=0.8):\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    train_size = int(df.shape[0] * r)\n",
    "    train, test = df.loc[0:train_size], df.loc[train_size:]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def split_XY(df):\n",
    "    df_X = df.drop([\"Loan_Status_Y\"], axis=1)\n",
    "    df_Y = df[\"Loan_Status_Y\"]\n",
    "    return df_X, df_Y\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Task3 split the dataset into X_train, X_test, y_train, y_test\n",
    "# Optional: you can also use normalization\n",
    "################################################################################\n",
    "\n",
    "\n",
    "df_Yes = df[df[\"Loan_Status_Y\"] == 1]\n",
    "df_No = df[df[\"Loan_Status_Y\"] == 0]\n",
    "train_Yes, test_Yes = split(df_Yes, 0.8)\n",
    "train_No, test_No = split(df_No, 0.8)\n",
    "train = pd.concat([train_Yes, train_No])\n",
    "test = pd.concat([test_Yes, test_No])\n",
    "train_X, train_Y = split_XY(test)\n",
    "test_X, test_Y = split_XY(test)\n",
    "\n",
    "train_X.head()\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Logistic import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Task4 train your model and plot the loss curve of training\n",
    "# You need to complete the Logistic.py file\n",
    "# model = LogisticRegression()\n",
    "################################################################################\n",
    "\n",
    "model = LogisticRegression(penalty=\"l2\", gamma=2e-5, fit_intercept=True)\n",
    "\n",
    "loss, acc = model.fit(\n",
    "    train_X, train_Y, lr=0.01, tol=1e-8, max_iter=10**5, test_X=test_X, test_y=test_Y\n",
    ")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "(h1,) = plt.plot(loss, \"b\", label=\"loss\")\n",
    "plt.twinx()\n",
    "plt.ylabel(\"acc\")\n",
    "(h2,) = plt.plot(acc, \"r\", label=\"acc\")\n",
    "plt.legend(handles=[h1, h2], loc=\"best\")\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Task5 compare the accuracy(or other metrics you want) of test data with different parameters you train with\n",
    "################################################################################\n",
    "\n",
    "print(model.predict_acc(test_X, test_Y))\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "429c4da532d5a49305ad374da5bd9411413fc9c5f93bdb5e51c34bc796003ebd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
