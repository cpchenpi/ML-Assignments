
## 第9次作业

1. 记 ${err}^*({x})=1-\max _{c \in \mathcal{Y}} P(c \mid {x}), {err}({x})=1-\sum_c P(c \mid {x}) P(c \mid {z})$, 其中 ${z}$ 为 ${x}$ 的最近邻, 试证明在样本无穷多时
$$
{err}^*({x}) \leq {err}({x}) \leq {err}^*({x})\left(2-\frac{|\mathcal{Y}|}{|\mathcal{Y}|-1} \times {err}^*({x})\right)
$$

提示：柯西-施瓦兹不等式 $\left(\sum_i a_i\right)^2 \leq n\left(\sum_i a_i^2\right)$ 。
证明. 先证明左边不等式:
$$\begin{aligned}
{err}^*({x}) & =1-\max _{c \in \mathcal{Y}} P(c \mid {x})=1-\max _{c \in \mathcal{Y}} P(c \mid {x}) \cdot \sum_c P(c \mid {z}) \\
& =1-\sum_c \max _{c \in \mathcal{Y}} P(c \mid {x}) \cdot P(c \mid {z}) \\
& \leq 1-\sum_c P(c \mid {x}) \cdot P(c \mid {z})={err}^*({x})
\end{aligned}$$

令 $c^*=\arg \max _c P(c \mid {x})$, 再证明右边不等式:
$$
\begin{aligned}
{err}^*({x}) & =1-\sum_c P(c \mid {x}) \cdot P(c \mid {z}) \simeq 1-\sum_c P(c \mid {x})^2 \\
& \leq 1-P\left(c^* \mid {x}\right)^2-\sum_{c \neq c^*} P(c \mid {x})^2 \\
& \leq 1-P\left(c^* \mid {x}\right)^2-\frac{1}{|\mathcal{Y}|-1}\left(\sum_{c \neq c^*} P(c \mid {x})\right)^2 \\
& =1-P\left(c^* \mid {x}\right)^2-\frac{1}{|\mathcal{Y}|-1}\left(1-P\left(c^* \mid {x}\right)\right)^2 \\
& =\left(1-P\left(c^* \mid {x}\right)\right) \cdot\left(1+P\left(c^* \mid {x}\right)-\frac{1}{|\mathcal{Y}|-1}\left(1-P\left(c^* \mid {x}\right)\right)\right) \\
& =\left(1-P\left(c^* \mid {x}\right)\right) \cdot\left(2-\frac{|\mathcal{Y}|}{|\mathcal{Y}|-1}\left(1-P\left(c^* \mid {x}\right)\right)\right) \\
& ={err}^*({x}) \cdot\left(2-\frac{|\mathcal{Y}|}{|\mathcal{Y}|-1} \cdot {err}^*({x})\right)
\end{aligned}
$$

综上所述, 证毕!



2. 在实践中, 协方差矩阵 $\mathrm{XX}^{\top}$ 的特征值分解常由中心化后的样本矩阵 $\mathrm{X}$ 的奇异值分解替代, 试述其原因。

   解. 仅供参考, 言之成理即可。
   令 $\mathbf{X X}^{\top}$ 的特征值分解为
   $$
   \mathbf{X} \mathbf{X}^{\top}=\mathbf{Y} {\Lambda} \mathbf{Y}^{\top}
   $$

   令 $\mathbf{X}$ 的奇异值分解为 $\mathbf{U} {\Sigma} \mathbf{V}^{\top}$, 可得
   $$
   \mathbf{X} \mathbf{X}^{\top}=\mathbf{U} {\Sigma} \mathbf{V}^{\top}\left(\mathbf{U} {\Sigma} \mathbf{V}^{\top}\right)^{\top}=\mathbf{U} {\Sigma} \mathbf{V}^{\top} \mathbf{V} {\Sigma}^{\top} \mathbf{U}^{\top}
   $$

   因为 $\mathbf{X}$ 是经过中心化的样本矩阵, 因此 $\mathbf{V}^{\top} \mathbf{V}=\mathbf{I}, \mathbf{U}^{\top} \mathbf{U}=\mathbf{I}$, 所以
   $$
   \mathbf{X} \mathbf{X}^{\top}=\mathbf{U}\left({\Sigma} {\Sigma}^{\top}\right) \mathbf{U}^{\top}
   $$

   如果令 $\mathbf{Y}=\mathbf{U} 、 {\Lambda}={\Sigma} {\Sigma}^{\top}$, 不难发现式(1)和(2)是等价的, 也是就是协方差矩阵的特征值分解与中心化后的样本矩阵的奇异值分解其实是等价的。
   除此外, 相较于特征值分解, 奇异值分解的运算要更加高效, 节省存储空间。


3. $$
   \begin{array}{cl}
   \max _{\mathbf{W}} & {tr}\left(\mathbf{W}^{\top} \mathbf{X} \mathbf{X}^{\top} \mathbf{W}\right) \\
   \text { s.t. } & \mathbf{W}^{\top} \mathbf{W}=\mathbf{I}_{d^{\prime}}
   \end{array}
   $$

   解. 先将问题转化为等价问题,
   $$
   \begin{array}{cl}
   \min _{\mathbf{W}} & -{tr}\left(\mathbf{W}^{\top} \mathbf{X} \mathbf{X}^{\top} \mathbf{W}\right) \\
   \text { s.t. } & \mathbf{W}^{\top} \mathbf{W}=\mathbf{I}_{d^{\prime}}
   \end{array}
   $$

   然后使用拉格朗日乘子法, 构造拉格朗日函数
   $$
   L(\mathbf{W}, {\Lambda})=-{tr}\left(\mathbf{W}^{\top} \mathbf{X} \mathbf{X}^{\top} \mathbf{W}\right)+{tr}\left({\Lambda}\left(\mathbf{W}^{\top} \mathbf{W}-\mathbf{I}_{\mathbf{d}^{\prime}}\right)\right)
   $$

   其中, ${\Lambda}={diag}\left(\lambda_1, \cdots, \lambda_{d^{\prime}}\right)$, 于是令
   $$
   \begin{aligned}
   \frac{\partial L}{\partial \mathbf{W}} & =-\frac{\partial}{\partial \mathbf{W}} {tr}\left(\mathbf{W}^{\top} \mathbf{X} \mathbf{X}^{\top} \mathbf{W}\right)+\frac{\partial}{\partial \mathbf{W}} {tr}\left({\Lambda}\left(\mathbf{W}^{\top} \mathbf{W}-\mathbf{I}_{\mathbf{d}^{\prime}}\right)\right) \\
   & =-2 \mathbf{X} \mathbf{X}^{\top} \mathbf{W}+2 \mathbf{W} \mathbf{\Lambda} \\
   & =0
   \end{aligned}
   $$

   解得
   $$
   \mathbf{X} \mathbf{X}^{\top} \mathbf{W}=\mathbf{W} \mathbf{\Lambda}
   $$

   这意味着
   $$
   \mathbf{X X}^{\top} {w}_i=\lambda_i {w}_i
   $$

   也就是说, 取 $\mathbf{X} \mathbf{X}^{\top}$ 的最大的前 $d^{\prime}$ 个特征值所对应的特征向量即可得 $\mathbf{W}$ 。将之代入到目标函数即可得
   $$
   {tr}\left(\mathbf{W}^{\top} \mathbf{X} \mathbf{X}^{\top} \mathbf{W}\right)=\sum_{i=1}^{d^{\prime}} \lambda_{d^{\prime}}
   $$

## 第10次作业
1. [课本习题 11.5] 结合图 11.2, 试举例说明 $\mathbf{L}_1$ 正则化在何种情形下不能产生稀疏解。解. 如图所示, 当平方差误差项等值线的斜率较大的时候, 其与 $L_1$ 范数等值线的交点就不再位于坐标轴上, 因此将无法产生稀疏解。
   ![image-20240104164914475](HW9&10%E8%A7%A3%E7%AD%94.assets/image-20240104164914475.png)

   ![image-20240104165050551](HW9&10%E8%A7%A3%E7%AD%94.assets/image-20240104165050551.png)

2. [课本习题 11.7] 试述直接求解 $\mathbf{L}_0$ 范数正则化会遇到的困难。

   解. $\mathrm{L}_0$ 范数是统计向量非零元素的个数, 不连续、不可微、非凸, 无法通过凸优化的方式求解,需要采用遍历方式才能找到最优解, 因此难度是 NP-难的。

3. [PPT 20 页] 证明回归和对率回归的损失函数的梯度是否满足 L-Lipschitz 条件, 并求出 $\mathbf{L}$ 。

   证明. 先证明线性回归函数, 其损失函数为
   $$
   E({w})=({y}-\mathbf{X} {w})^{\top}({y}-\mathbf{X} {w})
   $$

   不难发现该函数为凸函数, 其微分算子 $\nabla E$ 表示为
   $$
   \nabla E({w})=2 \mathbf{X}^{\top}(\mathbf{X} {w}-{y})
   $$

   对于 $\forall {w}, {w}^{\prime}$, 都有
   $$
   \begin{aligned}
   \left\|\nabla E({w})-\nabla E\left({w}^{\prime}\right)\right\|_2 & =\left\|2 \mathbf{X}^{\top} \mathbf{X}\left({w}-{w}^{\prime}\right)\right\|_2 \\
   & \leq 2\left\|\mathbf{X}^{\top} \mathbf{X}\right\|_2 \cdot\left\|{w}-{w}^{\prime}\right\|_2
   \end{aligned}
   $$

   令 $L=2\left\|\mathbf{X}^{\top} \mathbf{X}\right\|_2>0$, 可以发现线性回归函数的损失函数满足 L-Lipschitz 条件。
   接着证明对率回归函数, 其损失函数为
   $$
   \ell({\beta})=\sum_{i=1}^m\left(-y_i {\beta}^{\top} {x}_i+\ln \left(1+e^{{\beta}^{\top} {x}_i}\right)\right)
   $$

   该函数是关于 ${\beta}$ 的高阶可导连续凸函数, 其微分算子 $\nabla \ell$ 表示为
   $$
   \nabla \ell({\beta})=\sum_{i=1}^m\left(-y_i {x}_i+\frac{{x}_i e^{{\beta}^{\top} {x}_i}}{1+e^{{\beta}^{\top} {x}_i}}\right)=\sum_{i=1}^m\left(\frac{1}{1+e^{-{\beta}^{\top} {x}_i}}-y_i\right) {x}_i
   $$

   对于 $\forall {\beta}, {\beta}^{\prime}$ ，都有
   $$
   \left\|\nabla \ell({\beta})-\nabla \ell\left({\beta}^{\prime}\right)\right\|_2=\left\|\sum_i\left(\frac{1}{1+e^{-{\beta}^{\top} {x}_i}}-\frac{1}{1+e^{-{\beta}^{\prime \top} {x}_i}}\right) {x}_i\right\|_2
   $$

   注意到 Sigmod 函数 $f(x)=\frac{1}{1+e^{-x}}$ 上任意两点连线的斜率小于等于 $f^{\prime}(0)$, 因此可知
   $$
   \frac{1}{1+e^{-{\beta}^{\top} {x}_i}}-\frac{1}{1+e^{-{\beta}^{\prime \top} {x}_i}} \leq\left.\left(\frac{1}{1+e^{-{\beta}^{\top} {x}_i}}\right)^{\prime}\right|_{{\beta}^{\top} {x}_i=0}\left({\beta}^{\top}-{\beta}^{\prime^{\top}}\right) {x}_i=\frac{1}{4} {x}_i^{\top}\left({\beta}-{\beta}^{\prime}\right)
   $$

   因此可得
   $$
   \begin{aligned}
   \left\|\nabla \ell({\beta})-\nabla \ell\left({\beta}^{\prime}\right)\right\|_2 & \leq\left\|\sum_i \frac{1}{4} {x}_i^{\top}\left({\beta}-{\beta}^{\prime}\right) {x}_i\right\|_2 \\
   & \leq \frac{1}{4}\left\|\sum_i {x}_i^{\top} {x}_{{i}}\right\|_2 \cdot\left\|{\beta}-{\beta}^{\prime}\right\|_2
   \end{aligned}
   $$

   令 $L=\frac{1}{4}\left\|\sum_i {x}_i^{\top} {x}_{{i}}\right\|_2>0$, 可以发现对率回归函数的损失函数满足 L-Lipschitz 条件。